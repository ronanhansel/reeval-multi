{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a0296cc1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/reeval/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "import os\n",
        "import json\n",
        "import gc\n",
        "from torch.distributions import Bernoulli\n",
        "from torch.optim import LBFGS\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import pearsonr\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from multiprocessing import Manager\n",
        "import multiprocessing as mp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from tueplots import bundles\n",
        "bundles.icml2024()\n",
        "\n",
        "from torchmetrics import AUROC\n",
        "auroc = AUROC(task=\"binary\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "def visualize_response_matrix(results, value, filename):\n",
        "    # Extract the groups labels in the order of the columns\n",
        "    group_values = results.columns.get_level_values(\"scenario\")\n",
        "\n",
        "    # Identify the boundaries where the group changes\n",
        "    boundaries = []\n",
        "    for i in range(1, len(group_values)):\n",
        "        if group_values[i] != group_values[i - 1]:\n",
        "            boundaries.append(i - 0.5)  # using 0.5 to place the line between columns\n",
        "\n",
        "    # Visualize the results with a matrix: red is 0, white is -1 and blue is 1\n",
        "    cmap = mcolors.ListedColormap([\"white\", \"red\", \"blue\"])\n",
        "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
        "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    # Calculate midpoints for each group label\n",
        "    groups_list = list(group_values)\n",
        "    group_names = []\n",
        "    group_midpoints = []\n",
        "    current_group = groups_list[0]\n",
        "    start_index = 0\n",
        "    for i, grp in enumerate(groups_list):\n",
        "        if grp != current_group:\n",
        "            midpoint = (start_index + i - 1) / 2.0\n",
        "            group_names.append(current_group)\n",
        "            group_midpoints.append(midpoint)\n",
        "            current_group = grp\n",
        "            start_index = i\n",
        "    # Add the last group\n",
        "    midpoint = (start_index + len(groups_list) - 1) / 2.0\n",
        "    group_names.append(current_group)\n",
        "    group_midpoints.append(midpoint)\n",
        "\n",
        "    # Define the minimum spacing between labels (e.g., 100 units)\n",
        "    min_spacing = 100\n",
        "    last_label_pos = -float(\"inf\")\n",
        "    # Plot the matrix\n",
        "    with plt.rc_context(bundles.icml2024(usetex=True, family=\"serif\")):\n",
        "        fig, ax = plt.subplots(figsize=(20, 10))\n",
        "        cax = ax.matshow(value, aspect=\"auto\", cmap=cmap, norm=norm)\n",
        "\n",
        "        # Add vertical lines at each boundary\n",
        "        for b in boundaries:\n",
        "            ax.axvline(x=b, color=\"black\", linewidth=0.25, linestyle=\"--\", alpha=0.5)\n",
        "        \n",
        "        # Add group labels above the matrix, only if they're spaced enough apart\n",
        "        for name, pos in zip(group_names, group_midpoints):\n",
        "            if pos - last_label_pos >= min_spacing:\n",
        "                ax.text(pos, -5, name, ha='center', va='bottom', rotation=90, fontsize=3)\n",
        "                last_label_pos = pos\n",
        "\n",
        "        # Add model labels on the y-axis\n",
        "        ax.set_yticks(range(len(results.index)))\n",
        "        ax.set_yticklabels(results.index, fontsize=3)\n",
        "\n",
        "        # Add a colorbar\n",
        "        cbar = plt.colorbar(cax)\n",
        "        cbar.set_ticks([-1, 0, 1])\n",
        "        cbar.set_ticklabels([\"-1\", \"0\", \"1\"])\n",
        "        plt.savefig(filename, dpi=600, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "def trainer(parameters, optim, closure, n_iter=100, verbose=True):\n",
        "    pbar = tqdm(range(n_iter)) if verbose else range(n_iter)\n",
        "    for iteration in pbar:\n",
        "        if iteration > 0:\n",
        "            previous_parameters = [p.clone() for p in parameters]\n",
        "            previous_loss = loss.clone()\n",
        "        \n",
        "        loss = optim.step(closure)\n",
        "        \n",
        "        if iteration > 0:\n",
        "            d_loss = (previous_loss - loss).item()\n",
        "            d_parameters = sum(\n",
        "                torch.norm(prev - curr, p=2).item()\n",
        "                for prev, curr in zip(previous_parameters, parameters)\n",
        "            )\n",
        "            grad_norm = sum(torch.norm(p.grad, p=2).item() for p in parameters if p.grad is not None)\n",
        "            if verbose:\n",
        "                pbar.set_postfix({\"grad_norm\": grad_norm, \"d_parameter\": d_parameters, \"d_loss\": d_loss})\n",
        "            \n",
        "            if d_loss < 1e-5 and d_parameters < 1e-5 and grad_norm < 1e-5:\n",
        "                break\n",
        "    return parameters\n",
        "\n",
        "def compute_auc(probs, data, train_idtor, test_idtor):\n",
        "    train_probs = probs[train_idtor.bool()]\n",
        "    test_probs = probs[test_idtor.bool()]\n",
        "    train_labels = data[train_idtor.bool()]\n",
        "    test_labels = data[test_idtor.bool()]\n",
        "    train_auc = auroc(train_probs, train_labels)\n",
        "    test_auc = auroc(test_probs, test_labels)\n",
        "    print(f\"train auc: {train_auc}\")\n",
        "    print(f\"test auc: {test_auc}\")\n",
        "    \n",
        "    return train_auc, test_auc\n",
        "\n",
        "def compute_cttcorr(probs, data, train_idtor, test_idtor):\n",
        "    train_probs  = probs.clone()\n",
        "    test_probs   = probs.clone()\n",
        "    train_labels = data.clone()\n",
        "    test_labels  = data.clone()\n",
        "\n",
        "    train_mask = ~train_idtor.bool()\n",
        "    train_probs[train_mask]  = float('nan')\n",
        "    train_labels[train_mask] = float('nan')\n",
        "\n",
        "    test_mask = ~test_idtor.bool()\n",
        "    test_probs[test_mask]   = float('nan')\n",
        "    test_labels[test_mask]  = float('nan')\n",
        "    \n",
        "    train_prob_ctt = torch.nanmean(train_probs, dim=1).detach().cpu().numpy()\n",
        "    train_label_ctt = torch.nanmean(train_labels, dim=1).detach().cpu().numpy()\n",
        "    train_mask = ~np.isnan(train_prob_ctt) & ~np.isnan(train_label_ctt)\n",
        "    train_cttcorr = pearsonr(train_prob_ctt[train_mask], train_label_ctt[train_mask]).statistic\n",
        "    \n",
        "    test_prob_ctt = torch.nanmean(test_probs, dim=1).detach().cpu().numpy()\n",
        "    test_label_ctt = torch.nanmean(test_labels, dim=1).detach().cpu().numpy()\n",
        "    test_mask = ~np.isnan(test_prob_ctt) & ~np.isnan(test_label_ctt)\n",
        "    test_cttcorr = pearsonr(test_prob_ctt[test_mask], test_label_ctt[test_mask]).statistic\n",
        "    \n",
        "    print(f\"train cttcorr: {train_cttcorr}\")\n",
        "    print(f\"test cttcorr: {test_cttcorr}\")\n",
        "\n",
        "    return train_cttcorr, test_cttcorr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13e77c09",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f\"../data/resmat.pkl\", \"rb\") as f:\n",
        "    results = pickle.load(f)\n",
        "\n",
        "dtype = torch.float64 if device.startswith(\"cuda\") else torch.float32\n",
        "\n",
        "# data_withnan, missing=nan\n",
        "# data_withneg1, missing=-1\n",
        "# data_with0, missing=0\n",
        "data_withnan = torch.tensor(results.values, dtype=dtype, device=device)\n",
        "data_idtor = (~torch.isnan(data_withnan)).to(dtype)\n",
        "data_withneg1 = data_withnan.nan_to_num(nan=-1.0)\n",
        "data_with0 = data_withneg1 * data_idtor\n",
        "data_with0 = data_with0.nan_to_num(nan=0.0)\n",
        "n_test_takers, n_items = data_with0.shape\n",
        "scenarios = results.columns.get_level_values(\"scenario\").unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "47d3fa9a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1.], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_with0.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e97c3541",
      "metadata": {},
      "source": [
        "Grid search for suitable dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b7859e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running MIRT with n_dimensions=2 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=2): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8111507892608643\n",
            "test auc: 0.7964804172515869\n",
            "train cttcorr: 0.7075257534721937\n",
            "test cttcorr: 0.6911825414658618\n",
            "n_dim=2: train_auc=0.8112, test_auc=0.7965, train_cttcorr=0.7075, test_cttcorr=0.6912, AIC=4902541.36, BIC=8039973.86\n",
            "\n",
            "=== Running MIRT with n_dimensions=3 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=3): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8115150928497314\n",
            "test auc: 0.7962170243263245\n",
            "train cttcorr: 0.7488648382438651\n",
            "test cttcorr: 0.7330264514074442\n",
            "n_dim=3: train_auc=0.8115, test_auc=0.7962, train_cttcorr=0.7489, test_cttcorr=0.7330, AIC=5057767.69, BIC=9242054.19\n",
            "\n",
            "=== Running MIRT with n_dimensions=4 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=4): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8144893646240234\n",
            "test auc: 0.799899697303772\n",
            "train cttcorr: 0.760732848443844\n",
            "test cttcorr: 0.7308601130991746\n",
            "n_dim=4: train_auc=0.8145, test_auc=0.7999, train_cttcorr=0.7607, test_cttcorr=0.7309, AIC=5226081.58, BIC=10457093.08\n",
            "\n",
            "=== Running MIRT with n_dimensions=5 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=5): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.813225507736206\n",
            "test auc: 0.7981082797050476\n",
            "train cttcorr: 0.7325475351957202\n",
            "test cttcorr: 0.7112201937502924\n",
            "n_dim=5: train_auc=0.8132, test_auc=0.7981, train_cttcorr=0.7325, test_cttcorr=0.7112, AIC=5365760.34, BIC=11643083.84\n",
            "\n",
            "=== Running MIRT with n_dimensions=6 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=6): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8173526525497437\n",
            "test auc: 0.8014328479766846\n",
            "train cttcorr: 0.7728985427960633\n",
            "test cttcorr: 0.7665988195566465\n",
            "n_dim=6: train_auc=0.8174, test_auc=0.8014, train_cttcorr=0.7729, test_cttcorr=0.7666, AIC=5500665.81, BIC=12824976.81\n",
            "\n",
            "=== Running MIRT with n_dimensions=7 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=7): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.52s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8166617751121521\n",
            "test auc: 0.8010513782501221\n",
            "train cttcorr: 0.8089399015498351\n",
            "test cttcorr: 0.8004653915244822\n",
            "n_dim=7: train_auc=0.8167, test_auc=0.8011, train_cttcorr=0.8089, test_cttcorr=0.8005, AIC=5674683.79, BIC=14045581.79\n",
            "\n",
            "=== Running MIRT with n_dimensions=8 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=8): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.52s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8167843222618103\n",
            "test auc: 0.8015276193618774\n",
            "train cttcorr: 0.7924439994092634\n",
            "test cttcorr: 0.7863423710660855\n",
            "n_dim=8: train_auc=0.8168, test_auc=0.8015, train_cttcorr=0.7924, test_cttcorr=0.7863, AIC=5817555.22, BIC=15235028.22\n",
            "\n",
            "=== Running MIRT with n_dimensions=9 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=9): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8176456689834595\n",
            "test auc: 0.8021864891052246\n",
            "train cttcorr: 0.8291225554835577\n",
            "test cttcorr: 0.815854001696239\n",
            "n_dim=9: train_auc=0.8176, test_auc=0.8022, train_cttcorr=0.8291, test_cttcorr=0.8159, AIC=5995623.37, BIC=16459944.37\n",
            "\n",
            "=== Running MIRT with n_dimensions=10 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=10): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.54s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8153287172317505\n",
            "test auc: 0.7995522022247314\n",
            "train cttcorr: 0.8133266209595373\n",
            "test cttcorr: 0.793146471314127\n",
            "n_dim=10: train_auc=0.8153, test_auc=0.7996, train_cttcorr=0.8133, test_cttcorr=0.7931, AIC=6135275.69, BIC=17646331.69\n",
            "\n",
            "=== Running MIRT with n_dimensions=11 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches (dim=11): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.54s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train auc: 0.8185120224952698\n",
            "test auc: 0.8026008009910583\n",
            "train cttcorr: 0.7942789220727466\n",
            "test cttcorr: 0.7823387281679738\n",
            "n_dim=11: train_auc=0.8185, test_auc=0.8026, train_cttcorr=0.7943, test_cttcorr=0.7823, AIC=6281398.70, BIC=18838912.70\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "results_dim = []\n",
        "\n",
        "for n_dimensions in range(2, 12):\n",
        "    print(f\"\\n=== Running MIRT with n_dimensions={n_dimensions} ===\")\n",
        "    # --- Setup ---\n",
        "    n_test_takers = 183\n",
        "    n_items = 78712\n",
        "\n",
        "    # Mask generation\n",
        "    valid_condition = False\n",
        "    trial = 0\n",
        "    while not valid_condition:\n",
        "        train_idtor = torch.bernoulli(data_idtor * 0.8).int()\n",
        "        test_idtor = data_idtor - train_idtor\n",
        "        valid_condition = (train_idtor.sum(axis=1) != 0).all() and (train_idtor.sum(axis=0) != 0).all()\n",
        "        trial += 1\n",
        "\n",
        "    # Stage 1: Item calibration\n",
        "    n_mc_samples = 150\n",
        "    thetas_nuisance = torch.randn(n_mc_samples, n_test_takers, n_dimensions, device=device)\n",
        "    a_params = torch.randn(n_items, n_dimensions, requires_grad=True, device=device)\n",
        "    ds = torch.randn(n_items, requires_grad=True, device=device)\n",
        "    B = 50000\n",
        "    for i in tqdm(range(0, n_items, B), desc=f\"Stage 1: Calibrating Item Batches (dim={n_dimensions})\"):\n",
        "        current_B = min(B, n_items - i)\n",
        "        a_params_batch = a_params[i:i+current_B].clone().detach().requires_grad_(True)\n",
        "        ds_batch = ds[i:i+current_B].clone().detach().requires_grad_(True)\n",
        "        data_batch = data_with0[:, i:i+current_B]\n",
        "        train_idtor_batch = train_idtor[:, i:i+current_B]\n",
        "        optim_items = LBFGS([a_params_batch, ds_batch], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
        "        def closure_items():\n",
        "            optim_items.zero_grad()\n",
        "            a_params_constrained = torch.clamp(a_params_batch, min=0)\n",
        "            logits = torch.matmul(thetas_nuisance, a_params_constrained.T) - ds_batch[None, None, :]\n",
        "            probs = torch.sigmoid(logits)\n",
        "            log_likelihoods = Bernoulli(probs=probs).log_prob(data_batch[None, :, :]) * train_idtor_batch[None, :, :]\n",
        "            loss = -log_likelihoods.sum() / (train_idtor_batch.sum() * n_mc_samples)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "        optim_items.step(closure_items)\n",
        "        a_params.data[i:i+current_B] = a_params_batch.data\n",
        "        ds.data[i:i+current_B] = ds_batch.data\n",
        "\n",
        "    a_params_calibrated_unrotated = a_params.detach()\n",
        "    ds_calibrated = ds.detach()\n",
        "    a_params_np = a_params_calibrated_unrotated.cpu().numpy()\n",
        "    rotator = Rotator(method='varimax')\n",
        "    rotated_a_params = rotator.fit_transform(a_params_np)\n",
        "    a_params_calibrated = torch.tensor(rotated_a_params, device=device, dtype=torch.float32)\n",
        "\n",
        "    # Stage 2: Person calibration\n",
        "    thetas = torch.randn(n_test_takers, n_dimensions, requires_grad=True, device=device)\n",
        "    optim_thetas = LBFGS([thetas], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
        "    def closure_thetas():\n",
        "        optim_thetas.zero_grad()\n",
        "        thetas_constrained = torch.clamp(thetas, min=0)\n",
        "        a_params_constrained = torch.clamp(a_params_calibrated, min=0)\n",
        "        logits = torch.matmul(thetas_constrained, a_params_constrained.T) - ds_calibrated[None, :]\n",
        "        probs = torch.sigmoid(logits)\n",
        "        log_likelihoods = Bernoulli(probs=probs).log_prob(data_with0) * train_idtor\n",
        "        loss = -log_likelihoods.sum() / train_idtor.sum()\n",
        "        loss.backward()\n",
        "        return loss\n",
        "    optim_thetas.step(closure_thetas)\n",
        "    thetas_final = thetas.detach()\n",
        "    a_params_final = a_params_calibrated\n",
        "    ds_final = ds_calibrated\n",
        "\n",
        "    # Evaluation\n",
        "    thetas_constrained_final = torch.clamp(thetas_final, min=0)\n",
        "    a_params_constrained_final = torch.clamp(a_params_final, min=0)\n",
        "    logits = torch.matmul(thetas_constrained_final, a_params_constrained_final.T) - ds_final[None, :]\n",
        "    probs = torch.sigmoid(logits)\n",
        "    train_auc, test_auc = compute_auc(probs, data_with0, train_idtor, test_idtor)\n",
        "    train_cttcorr, test_cttcorr = compute_cttcorr(probs, data_with0, train_idtor, test_idtor)\n",
        "\n",
        "    # Model fit indices\n",
        "    num_item_params = n_items * (n_dimensions + 1)\n",
        "    num_person_params = n_test_takers * n_dimensions\n",
        "    k = num_item_params + num_person_params\n",
        "    n_obs = train_idtor.sum().item()\n",
        "    with torch.no_grad():\n",
        "        log_likelihood = Bernoulli(probs=probs).log_prob(data_with0) * train_idtor\n",
        "        total_log_likelihood = log_likelihood.sum()\n",
        "    aic = 2 * k - 2 * total_log_likelihood\n",
        "    bic = k * torch.log(torch.tensor(n_obs, dtype=torch.float32)) - 2 * total_log_likelihood\n",
        "\n",
        "    # Save results\n",
        "    results_dim.append({\n",
        "        \"n_dimensions\": n_dimensions,\n",
        "        \"train_auc\": float(train_auc),\n",
        "        \"test_auc\": float(test_auc),\n",
        "        \"train_cttcorr\": float(train_cttcorr),\n",
        "        \"test_cttcorr\": float(test_cttcorr),\n",
        "        \"log_likelihood\": float(total_log_likelihood),\n",
        "        \"AIC\": float(aic),\n",
        "        \"BIC\": float(bic)\n",
        "    })\n",
        "    print(f\"n_dim={n_dimensions}: train_auc={train_auc:.4f}, test_auc={test_auc:.4f}, train_cttcorr={train_cttcorr:.4f}, test_cttcorr={test_cttcorr:.4f}, AIC={aic:.2f}, BIC={bic:.2f}\")\n",
        "\n",
        "# Save all results to file\n",
        "os.makedirs(\"../result\", exist_ok=True)\n",
        "import json\n",
        "with open(\"../result/mirt_dim_results.json\", \"w\") as f:\n",
        "    json.dump(results_dim, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d3a9c98e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 0 valid condition: True\n",
            "Starting Stage 1: Fitting item parameters (a_params and ds)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage 1: Calibrating Item Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage 1 Finished (unrotated).\n",
            "\n",
            "--- Performing Factor Rotation ---\n",
            "Rotation complete. The rotated matrix is now the interpretable latent Q-matrix.\n",
            "\n",
            "Starting Stage 2: Fitting person parameters (thetas)...\n",
            "Stage 2 Finished. Training complete.\n",
            "train auc: 0.8181132674217224\n",
            "test auc: 0.8022111654281616\n",
            "train cttcorr: 0.8102029631594286\n",
            "test cttcorr: 0.786183379343087\n",
            "\n",
            "--- Post-Hoc Analysis ---\n",
            "Theta Correlation Matrix:\n",
            "[[ 1.          0.13031827  0.18375701  0.10735548  0.1306726   0.17823001\n",
            "   0.08648952  0.22196541  0.29091689]\n",
            " [ 0.13031827  1.          0.22138605  0.14695814  0.06316584  0.06822706\n",
            "   0.14489865  0.23206715  0.11745934]\n",
            " [ 0.18375701  0.22138605  1.          0.1213672   0.13798604  0.20337862\n",
            "   0.12705691  0.13689088  0.17047772]\n",
            " [ 0.10735548  0.14695814  0.1213672   1.          0.09469717  0.11417649\n",
            "   0.20637249 -0.01874886  0.01321276]\n",
            " [ 0.1306726   0.06316584  0.13798604  0.09469717  1.          0.23768495\n",
            "   0.11290381  0.10915652  0.11194   ]\n",
            " [ 0.17823001  0.06822706  0.20337862  0.11417649  0.23768495  1.\n",
            "   0.05523006  0.1567782   0.18675409]\n",
            " [ 0.08648952  0.14489865  0.12705691  0.20637249  0.11290381  0.05523006\n",
            "   1.          0.10838332  0.13205551]\n",
            " [ 0.22196541  0.23206715  0.13689088 -0.01874886  0.10915652  0.1567782\n",
            "   0.10838332  1.          0.22705804]\n",
            " [ 0.29091689  0.11745934  0.17047772  0.01321276  0.11194     0.18675409\n",
            "   0.13205551  0.22705804  1.        ]]\n",
            "\n",
            "Interpretation:\n",
            "- Values close to 0 mean the dimensions are distinct.\n",
            "- Values close to 1 or -1 mean the dimensions are highly related.\n",
            "\n",
            "--- Model Fit Indices ---\n",
            "Number of parameters (k): 788767\n",
            "Number of observations (n): 4266271\n",
            "\n",
            "Total Log-Likelihood: -2201784.08\n",
            "AIC: 5981102.16\n",
            "BIC: 16445083.16\n",
            "\n",
            "Reminder: Lower AIC/BIC values indicate a better model fit.\n"
          ]
        }
      ],
      "source": [
        "# <<< Make sure you have factor_analyzer installed: pip install factor_analyzer >>>\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.distributions import Bernoulli\n",
        "from torch.optim import LBFGS\n",
        "from tqdm import tqdm\n",
        "from factor_analyzer.rotator import Rotator\n",
        "import gc\n",
        "\n",
        "# Assume prerequisite data tensors are loaded...\n",
        "# device, data_with0, data_idtor, n_test_takers, n_items\n",
        "\n",
        "# ====================================================================================\n",
        "# 1. SETUP & DATA SIMULATION\n",
        "# ====================================================================================\n",
        "\n",
        "n_test_takers = 183\n",
        "n_items = 78712\n",
        "# <<< We set the number of dimensions we want to DISCOVER >>>\n",
        "n_dimensions = 9\n",
        "\n",
        "# ====================================================================================\n",
        "# 3. MIRT MODEL TRAINING (Exploratory Approach)\n",
        "# ====================================================================================\n",
        "\n",
        "# Apply random train/test mask to the matrix\n",
        "valid_condition = False\n",
        "trial = 0\n",
        "while not valid_condition:\n",
        "    train_idtor = torch.bernoulli(data_idtor * 0.8).int()\n",
        "    test_idtor = data_idtor - train_idtor\n",
        "    valid_condition = (train_idtor.sum(axis=1) != 0).all() and (train_idtor.sum(axis=0) != 0).all()\n",
        "    print(f\"trial {trial} valid condition: {valid_condition}\")\n",
        "    trial += 1\n",
        "\n",
        "# --- STAGE 1: Fit Item Parameters (a_params and ds) ---\n",
        "print(\"Starting Stage 1: Fitting item parameters (a_params and ds)...\")\n",
        "\n",
        "n_mc_samples = 150\n",
        "thetas_nuisance = torch.randn(n_mc_samples, n_test_takers, n_dimensions, device=device)\n",
        "\n",
        "a_params = torch.randn(n_items, n_dimensions, requires_grad=True, device=device)\n",
        "ds = torch.randn(n_items, requires_grad=True, device=device)\n",
        "\n",
        "B = 50000\n",
        "for i in tqdm(range(0, n_items, B), desc=\"Stage 1: Calibrating Item Batches\"):\n",
        "    current_B = min(B, n_items - i)\n",
        "    a_params_batch = a_params[i:i+current_B].clone().detach().requires_grad_(True)\n",
        "    ds_batch = ds[i:i+current_B].clone().detach().requires_grad_(True)\n",
        "\n",
        "    data_batch = data_with0[:, i:i+current_B]\n",
        "    train_idtor_batch = train_idtor[:, i:i+current_B]\n",
        "    \n",
        "    optim_items = LBFGS([a_params_batch, ds_batch], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
        "\n",
        "    def closure_items():\n",
        "        optim_items.zero_grad()\n",
        "        \n",
        "        # <<< CHANGE: Removed the Q-matrix masking. We now estimate a dense matrix. >>>\n",
        "        a_params_constrained = torch.clamp(a_params_batch, min=0)\n",
        "        \n",
        "        logits = torch.matmul(thetas_nuisance, a_params_constrained.T) - ds_batch[None, None, :]\n",
        "        probs = torch.sigmoid(logits)\n",
        "        \n",
        "        log_likelihoods = Bernoulli(probs=probs).log_prob(data_batch[None, :, :]) * train_idtor_batch[None, :, :]\n",
        "        loss = -log_likelihoods.sum() / (train_idtor_batch.sum() * n_mc_samples)\n",
        "        \n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    optim_items.step(closure_items)\n",
        "    \n",
        "    a_params.data[i:i+current_B] = a_params_batch.data\n",
        "    ds.data[i:i+current_B] = ds_batch.data\n",
        "\n",
        "a_params_calibrated_unrotated = a_params.detach()\n",
        "ds_calibrated = ds.detach()\n",
        "print(\"Stage 1 Finished (unrotated).\")\n",
        "\n",
        "# <<< NEW STEP: Perform Post-Hoc Factor Rotation to create the latent Q-matrix >>>\n",
        "print(\"\\n--- Performing Factor Rotation ---\")\n",
        "a_params_np = a_params_calibrated_unrotated.cpu().numpy()\n",
        "rotator = Rotator(method='varimax')\n",
        "rotated_a_params = rotator.fit_transform(a_params_np)\n",
        "print(\"Rotation complete. The rotated matrix is now the interpretable latent Q-matrix.\")\n",
        "a_params_calibrated = torch.tensor(rotated_a_params, device=device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# --- STAGE 2: Fit Person Parameters (thetas) ---\n",
        "print(\"\\nStarting Stage 2: Fitting person parameters (thetas)...\")\n",
        "\n",
        "thetas = torch.randn(n_test_takers, n_dimensions, requires_grad=True, device=device)\n",
        "optim_thetas = LBFGS([thetas], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
        "\n",
        "def closure_thetas():\n",
        "    optim_thetas.zero_grad()\n",
        "    \n",
        "    thetas_constrained = torch.clamp(thetas, min=0)\n",
        "    # <<< CHANGE: Use the new rotated a_params without Q-matrix masking >>>\n",
        "    a_params_constrained = torch.clamp(a_params_calibrated, min=0)\n",
        "    \n",
        "    logits = torch.matmul(thetas_constrained, a_params_constrained.T) - ds_calibrated[None, :]\n",
        "    probs = torch.sigmoid(logits)\n",
        "    \n",
        "    log_likelihoods = Bernoulli(probs=probs).log_prob(data_with0) * train_idtor\n",
        "    loss = -log_likelihoods.sum() / train_idtor.sum()\n",
        "    \n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "optim_thetas.step(closure_thetas)\n",
        "\n",
        "thetas_final = thetas.detach()\n",
        "a_params_final = a_params_calibrated # Use the rotated parameters\n",
        "ds_final = ds_calibrated\n",
        "print(\"Stage 2 Finished. Training complete.\")\n",
        "\n",
        "# --- 4. EVALUATION ---\n",
        "thetas_constrained_final = torch.clamp(thetas_final, min=0)\n",
        "# <<< CHANGE: Use final rotated a_params without Q-matrix masking >>>\n",
        "a_params_constrained_final = torch.clamp(a_params_final, min=0)\n",
        "\n",
        "logits = torch.matmul(thetas_constrained_final, a_params_constrained_final.T) - ds_final[None, :]\n",
        "probs = torch.sigmoid(logits)\n",
        "\n",
        "train_auc, test_auc = compute_auc(probs, data_with0, train_idtor, test_idtor)\n",
        "train_cttcorr, test_cttcorr = compute_cttcorr(probs, data_with0, train_idtor, test_idtor)\n",
        "\n",
        "# --- 5. POST-HOC ANALYSIS ---\n",
        "print(\"\\n--- Post-Hoc Analysis ---\")\n",
        "\n",
        "# Ensure the final thetas are on the CPU and converted to a NumPy array\n",
        "thetas_np = thetas_final.cpu().numpy()\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "# rowvar=False is important: it tells numpy that your variables are columns, not rows.\n",
        "theta_correlation_matrix = np.corrcoef(thetas_np, rowvar=False)\n",
        "\n",
        "print(\"Theta Correlation Matrix:\")\n",
        "print(theta_correlation_matrix)\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"- Values close to 0 mean the dimensions are distinct.\")\n",
        "print(\"- Values close to 1 or -1 mean the dimensions are highly related.\")\n",
        "import torch\n",
        "\n",
        "# --- 6. MODEL FIT CALCULATION ---\n",
        "print(\"\\n--- Model Fit Indices ---\")\n",
        "\n",
        "# 1. Define Model Complexity (k = number of parameters)\n",
        "num_item_params = n_items * (n_dimensions + 1)  # (a * K) + d\n",
        "num_person_params = n_test_takers * n_dimensions # theta * K\n",
        "k = num_item_params + num_person_params\n",
        "print(f\"Number of parameters (k): {k}\")\n",
        "\n",
        "# 2. Define Number of Observations (n = number of responses in training set)\n",
        "n = train_idtor.sum().item()\n",
        "print(f\"Number of observations (n): {n}\")\n",
        "\n",
        "# 3. Calculate Final Log-Likelihood on the Training Data\n",
        "with torch.no_grad(): # We don't need to compute gradients here\n",
        "    # Use the final, constrained parameters\n",
        "    thetas_constrained_final = torch.clamp(thetas_final, min=0)\n",
        "    \n",
        "    # <<< CORRECTED LINE: Removed the Q-matrix masking >>>\n",
        "    a_params_constrained_final = torch.clamp(a_params_final, min=0)\n",
        "    \n",
        "    # Calculate probabilities for the training data\n",
        "    logits = torch.matmul(thetas_constrained_final, a_params_constrained_final.T) - ds_final[None, :]\n",
        "    probs = torch.sigmoid(logits)\n",
        "    \n",
        "    # Calculate the log-likelihood only on the training responses\n",
        "    log_likelihood = Bernoulli(probs=probs).log_prob(data_with0) * train_idtor\n",
        "    total_log_likelihood = log_likelihood.sum()\n",
        "\n",
        "# 4. Calculate AIC and BIC\n",
        "aic = 2 * k - 2 * total_log_likelihood\n",
        "bic = k * torch.log(torch.tensor(n, dtype=torch.float32)) - 2 * total_log_likelihood\n",
        "\n",
        "print(f\"\\nTotal Log-Likelihood: {total_log_likelihood.item():.2f}\")\n",
        "print(f\"AIC: {aic.item():.2f}\")\n",
        "print(f\"BIC: {bic.item():.2f}\")\n",
        "print(\"\\nReminder: Lower AIC/BIC values indicate a better model fit.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9f2feb90",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Interpreting 9 Discovered Dimensions ---\n",
            "\n",
            "--- Analysis for Dim_1 ---\n",
            "Top contributing scenarios for Dim_1:\n",
            "scenario\n",
            "civil_comments    10293\n",
            "mmlu               4664\n",
            "wikifact           1979\n",
            "air_bench_2024     1732\n",
            "imdb               1270\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_2 ---\n",
            "Top contributing scenarios for Dim_2:\n",
            "scenario\n",
            "civil_comments    9997\n",
            "mmlu              4691\n",
            "wikifact          1924\n",
            "air_bench_2024    1724\n",
            "imdb              1320\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_3 ---\n",
            "Top contributing scenarios for Dim_3:\n",
            "scenario\n",
            "civil_comments    10065\n",
            "mmlu               4574\n",
            "wikifact           1905\n",
            "air_bench_2024     1747\n",
            "babi_qa            1255\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_4 ---\n",
            "Top contributing scenarios for Dim_4:\n",
            "scenario\n",
            "civil_comments    10080\n",
            "mmlu               4661\n",
            "wikifact           1936\n",
            "air_bench_2024     1751\n",
            "imdb               1278\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_5 ---\n",
            "Top contributing scenarios for Dim_5:\n",
            "scenario\n",
            "civil_comments    10073\n",
            "mmlu               4748\n",
            "wikifact           1937\n",
            "air_bench_2024     1715\n",
            "imdb               1281\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_6 ---\n",
            "Top contributing scenarios for Dim_6:\n",
            "scenario\n",
            "civil_comments    10059\n",
            "mmlu               4729\n",
            "wikifact           1927\n",
            "air_bench_2024     1741\n",
            "imdb               1306\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_7 ---\n",
            "Top contributing scenarios for Dim_7:\n",
            "scenario\n",
            "civil_comments    10133\n",
            "mmlu               4678\n",
            "wikifact           1941\n",
            "air_bench_2024     1698\n",
            "imdb               1205\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_8 ---\n",
            "Top contributing scenarios for Dim_8:\n",
            "scenario\n",
            "civil_comments    10148\n",
            "mmlu               4731\n",
            "wikifact           1959\n",
            "air_bench_2024     1773\n",
            "imdb               1305\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analysis for Dim_9 ---\n",
            "Top contributing scenarios for Dim_9:\n",
            "scenario\n",
            "civil_comments    10087\n",
            "mmlu               4615\n",
            "wikifact           1969\n",
            "air_bench_2024     1689\n",
            "babi_qa            1275\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- PREREQUISITES ---\n",
        "# Assume you have these variables from your previous script:\n",
        "# 1. rotated_a_params: The (78712, 9) numpy array of rotated loadings.\n",
        "# 2. An item_master_df that maps item_id to scenario, like we created before.\n",
        "#    If you don't have it, you can re-create it:\n",
        "test_data_df = pd.read_pickle(\"../data/resmat.pkl\")\n",
        "item_master_df = pd.DataFrame({\n",
        "\t'item_id': range(78712),\n",
        "\t'scenario': test_data_df.columns.get_level_values('scenario')\n",
        "})\n",
        "# ----------------------------------------------------\n",
        "\n",
        "print(\"--- Interpreting 9 Discovered Dimensions ---\")\n",
        "\n",
        "# Create a DataFrame of the loadings\n",
        "dim_names = [f'Dim_{i+1}' for i in range(n_dimensions)]\n",
        "loadings_df = pd.DataFrame(rotated_a_params, columns=dim_names)\n",
        "\n",
        "# Combine with scenario information\n",
        "interpretation_df = pd.concat([item_master_df, loadings_df], axis=1)\n",
        "\n",
        "# Set the loading threshold for interpretation\n",
        "loading_threshold = 0.40\n",
        "\n",
        "for dim_name in dim_names:\n",
        "    print(f\"\\n--- Analysis for {dim_name} ---\")\n",
        "    \n",
        "    # Find items that load strongly on this dimension\n",
        "    strong_loaders = interpretation_df[abs(interpretation_df[dim_name]) >= loading_threshold]\n",
        "    \n",
        "    if len(strong_loaders) == 0:\n",
        "        print(\"No datasets strongly load on this dimension.\")\n",
        "        continue\n",
        "    \n",
        "    # Count which scenarios are most represented in the strong loaders\n",
        "    scenario_counts = strong_loaders['scenario'].value_counts()\n",
        "    \n",
        "    print(f\"Top contributing scenarios for {dim_name}:\")\n",
        "    print(scenario_counts.head(5))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "reeval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

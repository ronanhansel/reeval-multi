{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "import os\n",
        "import json\n",
        "import gc\n",
        "from torch.distributions import Bernoulli\n",
        "from torch.optim import LBFGS\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import pearsonr\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from multiprocessing import Manager\n",
        "import multiprocessing as mp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from tueplots import bundles\n",
        "bundles.icml2024()\n",
        "\n",
        "from torchmetrics import AUROC\n",
        "auroc = AUROC(task=\"binary\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "def visualize_response_matrix(results, value, filename):\n",
        "    # Extract the groups labels in the order of the columns\n",
        "    group_values = results.columns.get_level_values(\"scenario\")\n",
        "\n",
        "    # Identify the boundaries where the group changes\n",
        "    boundaries = []\n",
        "    for i in range(1, len(group_values)):\n",
        "        if group_values[i] != group_values[i - 1]:\n",
        "            boundaries.append(i - 0.5)  # using 0.5 to place the line between columns\n",
        "\n",
        "    # Visualize the results with a matrix: red is 0, white is -1 and blue is 1\n",
        "    cmap = mcolors.ListedColormap([\"white\", \"red\", \"blue\"])\n",
        "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
        "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    # Calculate midpoints for each group label\n",
        "    groups_list = list(group_values)\n",
        "    group_names = []\n",
        "    group_midpoints = []\n",
        "    current_group = groups_list[0]\n",
        "    start_index = 0\n",
        "    for i, grp in enumerate(groups_list):\n",
        "        if grp != current_group:\n",
        "            midpoint = (start_index + i - 1) / 2.0\n",
        "            group_names.append(current_group)\n",
        "            group_midpoints.append(midpoint)\n",
        "            current_group = grp\n",
        "            start_index = i\n",
        "    # Add the last group\n",
        "    midpoint = (start_index + len(groups_list) - 1) / 2.0\n",
        "    group_names.append(current_group)\n",
        "    group_midpoints.append(midpoint)\n",
        "\n",
        "    # Define the minimum spacing between labels (e.g., 100 units)\n",
        "    min_spacing = 100\n",
        "    last_label_pos = -float(\"inf\")\n",
        "    # Plot the matrix\n",
        "    with plt.rc_context(bundles.icml2024(usetex=True, family=\"serif\")):\n",
        "        fig, ax = plt.subplots(figsize=(20, 10))\n",
        "        cax = ax.matshow(value, aspect=\"auto\", cmap=cmap, norm=norm)\n",
        "\n",
        "        # Add vertical lines at each boundary\n",
        "        for b in boundaries:\n",
        "            ax.axvline(x=b, color=\"black\", linewidth=0.25, linestyle=\"--\", alpha=0.5)\n",
        "        \n",
        "        # Add group labels above the matrix, only if they're spaced enough apart\n",
        "        for name, pos in zip(group_names, group_midpoints):\n",
        "            if pos - last_label_pos >= min_spacing:\n",
        "                ax.text(pos, -5, name, ha='center', va='bottom', rotation=90, fontsize=3)\n",
        "                last_label_pos = pos\n",
        "\n",
        "        # Add model labels on the y-axis\n",
        "        ax.set_yticks(range(len(results.index)))\n",
        "        ax.set_yticklabels(results.index, fontsize=3)\n",
        "\n",
        "        # Add a colorbar\n",
        "        cbar = plt.colorbar(cax)\n",
        "        cbar.set_ticks([-1, 0, 1])\n",
        "        cbar.set_ticklabels([\"-1\", \"0\", \"1\"])\n",
        "        plt.savefig(filename, dpi=600, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "def trainer(parameters, optim, closure, n_iter=100, verbose=True):\n",
        "    pbar = tqdm(range(n_iter)) if verbose else range(n_iter)\n",
        "    for iteration in pbar:\n",
        "        if iteration > 0:\n",
        "            previous_parameters = [p.clone() for p in parameters]\n",
        "            previous_loss = loss.clone()\n",
        "        \n",
        "        loss = optim.step(closure)\n",
        "        \n",
        "        if iteration > 0:\n",
        "            d_loss = (previous_loss - loss).item()\n",
        "            d_parameters = sum(\n",
        "                torch.norm(prev - curr, p=2).item()\n",
        "                for prev, curr in zip(previous_parameters, parameters)\n",
        "            )\n",
        "            grad_norm = sum(torch.norm(p.grad, p=2).item() for p in parameters if p.grad is not None)\n",
        "            if verbose:\n",
        "                pbar.set_postfix({\"grad_norm\": grad_norm, \"d_parameter\": d_parameters, \"d_loss\": d_loss})\n",
        "            \n",
        "            if d_loss < 1e-5 and d_parameters < 1e-5 and grad_norm < 1e-5:\n",
        "                break\n",
        "    return parameters\n",
        "\n",
        "def compute_auc(probs, data, train_idtor, test_idtor):\n",
        "    train_probs = probs[train_idtor.bool()]\n",
        "    test_probs = probs[test_idtor.bool()]\n",
        "    train_labels = data[train_idtor.bool()]\n",
        "    test_labels = data[test_idtor.bool()]\n",
        "    train_auc = auroc(train_probs, train_labels)\n",
        "    test_auc = auroc(test_probs, test_labels)\n",
        "    print(f\"train auc: {train_auc}\")\n",
        "    print(f\"test auc: {test_auc}\")\n",
        "    \n",
        "    return train_auc, test_auc\n",
        "\n",
        "def compute_cttcorr(probs, data, train_idtor, test_idtor):\n",
        "    train_probs  = probs.clone()\n",
        "    test_probs   = probs.clone()\n",
        "    train_labels = data.clone()\n",
        "    test_labels  = data.clone()\n",
        "\n",
        "    train_mask = ~train_idtor.bool()\n",
        "    train_probs[train_mask]  = float('nan')\n",
        "    train_labels[train_mask] = float('nan')\n",
        "\n",
        "    test_mask = ~test_idtor.bool()\n",
        "    test_probs[test_mask]   = float('nan')\n",
        "    test_labels[test_mask]  = float('nan')\n",
        "    \n",
        "    train_prob_ctt = torch.nanmean(train_probs, dim=1).detach().cpu().numpy()\n",
        "    train_label_ctt = torch.nanmean(train_labels, dim=1).detach().cpu().numpy()\n",
        "    train_mask = ~np.isnan(train_prob_ctt) & ~np.isnan(train_label_ctt)\n",
        "    train_cttcorr = pearsonr(train_prob_ctt[train_mask], train_label_ctt[train_mask]).statistic\n",
        "    \n",
        "    test_prob_ctt = torch.nanmean(test_probs, dim=1).detach().cpu().numpy()\n",
        "    test_label_ctt = torch.nanmean(test_labels, dim=1).detach().cpu().numpy()\n",
        "    test_mask = ~np.isnan(test_prob_ctt) & ~np.isnan(test_label_ctt)\n",
        "    test_cttcorr = pearsonr(test_prob_ctt[test_mask], test_label_ctt[test_mask]).statistic\n",
        "    \n",
        "    print(f\"train cttcorr: {train_cttcorr}\")\n",
        "    print(f\"test cttcorr: {test_cttcorr}\")\n",
        "\n",
        "    return train_cttcorr, test_cttcorr"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {},
      "id": "a0296cc1"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import float32\n",
        "\n",
        "\n",
        "with open(f\"../data/resmat.pkl\", \"rb\") as f:\n",
        "    results = pickle.load(f)\n",
        "\n",
        "dtype = torch.float64 if device.startswith(\"cuda\") else torch.float32\n",
        "\n",
        "# data_withnan, missing=nan\n",
        "# data_withneg1, missing=-1\n",
        "# data_with0, missing=0\n",
        "data_withnan = torch.tensor(results.values, dtype=dtype, device=device)\n",
        "data_idtor = (~torch.isnan(data_withnan)).to(dtype)\n",
        "data_withneg1 = data_withnan.nan_to_num(nan=-1.0)\n",
        "data_with0 = data_withneg1 * data_idtor\n",
        "data_with0 = data_with0.nan_to_num(nan=0.0)\n",
        "n_test_takers, n_items = data_with0.shape\n",
        "scenarios = results.columns.get_level_values(\"scenario\").unique()"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {},
      "id": "13e77c09"
    },
    {
      "cell_type": "code",
      "source": [
        "data_with0.unique()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "tensor([0., 1.], device='cuda:0', dtype=torch.float64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {},
      "id": "47d3fa9a"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.distributions import Bernoulli\n",
        "from torch.optim import LBFGS\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "import gc\n",
        "\n",
        "# Assume prerequisite functions like trainer() and data tensors are loaded\n",
        "# For this example, we will simulate the necessary data structures.\n",
        "\n",
        "# ====================================================================================\n",
        "# 1. SETUP & DATA SIMULATION (Replace with your actual data loading)\n",
        "# ====================================================================================\n",
        "\n",
        "n_test_takers = 183\n",
        "n_items = 78712  # <-- FIX 1: Set n_items to the total number of questions\n",
        "n_dimensions = 3\n",
        "\n",
        "# --- Create a map from each question to its scenario ---\n",
        "# CRITICAL STEP: You need to generate this map from your data.\n",
        "# We will simulate it here. Assume you have a DataFrame or list that\n",
        "# tells you which scenario each of the 78,712 questions belongs to.\n",
        "# For example, the first 5236 questions are from 'air_bench_2024' (scenario index 0),\n",
        "# the next 9558 are from 'babi_qa' (scenario index 1), etc.\n",
        "\n",
        "question_to_scenario_map = np.fromfile(\"../data/scenario_map.npy\", dtype=np.int32)\n",
        "\n",
        "\n",
        "# ====================================================================================\n",
        "# 2. EXPAND THE Q-MATRIX\n",
        "# ====================================================================================\n",
        "\n",
        "# Your original (22, 3) Q-Matrix for scenarios\n",
        "q_matrix_scenario = np.array([\n",
        "    [1, 0, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0],\n",
        "    [1, 0, 0], [1, 1, 0], [1, 0, 0], [1, 0, 1], [1, 0, 0],\n",
        "    [1, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 1],\n",
        "    [1, 0, 0], [1, 1, 0], [1, 1, 1], [1, 0, 0], [1, 0, 0],\n",
        "    [1, 0, 0], [1, 0, 0]\n",
        "])\n",
        "\n",
        "# FIX 2: Expand the Q-Matrix to the question level using the map\n",
        "print(\"Expanding Q-Matrix to question level...\")\n",
        "q_matrix_np_expanded = q_matrix_scenario[question_to_scenario_map]\n",
        "Q_matrix = torch.tensor(q_matrix_np_expanded, device=device, dtype=torch.float32)\n",
        "\n",
        "print(f\"Shape of expanded Q-Matrix: {Q_matrix.shape}\") # Should be (78712, 3)\n",
        "\n",
        "# ====================================================================================\n",
        "# 3. MIRT MODEL TRAINING (Now with correct shapes)\n",
        "# ====================================================================================\n",
        "\n",
        "# Apply random train/test mask to the matrix\n",
        "valid_condition = False\n",
        "trial = 0\n",
        "while not valid_condition:\n",
        "    train_idtor = torch.bernoulli(data_idtor * 0.8).int()\n",
        "    test_idtor = data_idtor - train_idtor\n",
        "    valid_condition = (train_idtor.sum(axis=1) != 0).all() and (train_idtor.sum(axis=0) != 0).all()\n",
        "    print(f\"trial {trial} valid condition: {valid_condition}\")\n",
        "    trial += 1\n",
        "\n",
        "# Hyperparameters for the two stages\n",
        "n_item_iterations = 100   # More iterations might be needed for the large number of items\n",
        "n_theta_iterations = 100 # Thetas can often be fit with more iterations\n",
        "lr_items = 0.01\n",
        "lr_thetas = 0.01\n",
        "\n",
        "\n",
        "# --- STAGE 1: Fit Item Parameters (a_params and ds) ---\n",
        "print(\"Starting Stage 1: Fitting item parameters (a_params and ds)...\")\n",
        "\n",
        "# We are only training these two parameters in this stage\n",
        "a_params = torch.randn(n_items, n_dimensions, requires_grad=True, device=device)\n",
        "ds = torch.randn(n_items, requires_grad=True, device=device)\n",
        "optim_items = Adam([a_params, ds], lr=lr_items)\n",
        "\n",
        "# Use a fixed, random set of thetas to approximate the expectation (Monte Carlo EM)\n",
        "n_mc_samples = 50 # Number of samples for the approximation. Can be reduced for speed.\n",
        "thetas_nuisance = torch.randn(n_mc_samples, n_test_takers, n_dimensions, device=device)\n",
        "\n",
        "for i in tqdm(range(n_item_iterations), desc=\"Stage 1: Calibrating Items\"):\n",
        "    optim_items.zero_grad()\n",
        "    \n",
        "    a_params_masked = a_params * Q_matrix\n",
        "    a_params_constrained = torch.clamp(a_params_masked, min=0)\n",
        "    \n",
        "    # Calculate logits using the fixed 'nuisance' thetas\n",
        "    # Shapes: (S, M, K) @ (K, N) -> (S, M, N), where S=n_mc_samples\n",
        "    logits = torch.matmul(thetas_nuisance, a_params_constrained.T) - ds[None, None, :]\n",
        "    probs = torch.sigmoid(logits)\n",
        "    \n",
        "    # Expand data and mask to match the nuisance sample dimension for loss calculation\n",
        "    log_likelihoods = Bernoulli(probs=probs).log_prob(data_with0[None, :, :]) * train_idtor[None, :, :]\n",
        "    loss = -log_likelihoods.sum() / (train_idtor.sum() * n_mc_samples)\n",
        "    \n",
        "    loss.backward()\n",
        "    optim_items.step()\n",
        "\n",
        "# Detach the now-calibrated item parameters to fix them for the next stage\n",
        "a_params_calibrated = a_params.detach()\n",
        "ds_calibrated = ds.detach()\n",
        "print(\"Stage 1 Finished.\")\n",
        "\n",
        "\n",
        "# --- STAGE 2: Fit Person Parameters (thetas) ---\n",
        "print(\"Starting Stage 2: Fitting person parameters (thetas)...\")\n",
        "\n",
        "# Initialize the real thetas we want to learn\n",
        "thetas = torch.randn(n_test_takers, n_dimensions, requires_grad=True, device=device)\n",
        "optim_thetas = Adam([thetas], lr=lr_thetas)\n",
        "\n",
        "for i in tqdm(range(n_theta_iterations), desc=\"Stage 2: Fitting Thetas\"):\n",
        "    optim_thetas.zero_grad()\n",
        "    \n",
        "    # Use the calibrated, fixed item parameters from Stage 1\n",
        "    # Note: No need for clamp here if a_params_calibrated is already positive, but it's a safe check\n",
        "    a_params_constrained = torch.clamp(a_params_calibrated * Q_matrix, min=0)\n",
        "    \n",
        "    logits = torch.matmul(thetas, a_params_constrained.T) - ds_calibrated[None, :]\n",
        "    probs = torch.sigmoid(logits)\n",
        "    \n",
        "    log_likelihoods = Bernoulli(probs=probs).log_prob(data_with0) * train_idtor\n",
        "    loss = -log_likelihoods.sum() / train_idtor.sum()\n",
        "    \n",
        "    loss.backward()\n",
        "    optim_thetas.step()\n",
        "\n",
        "thetas, a_params, ds = thetas.detach(), a_params_calibrated, ds_calibrated\n",
        "print(\"Stage 2 Finished. Training complete.\")\n",
        "\n",
        "# calculate metrics\n",
        "a_params_constrained = a_params * Q_matrix\n",
        "logits = torch.matmul(thetas, a_params_constrained.T) - ds[None, :]\n",
        "probs = torch.sigmoid(logits)\n",
        "\n",
        "train_auc, test_auc = compute_auc(probs, data_with0, train_idtor, test_idtor)\n",
        "\n",
        "train_cttcorr, test_cttcorr = compute_cttcorr(probs, data_with0, train_idtor, test_idtor)\n",
        "\n",
        "# del thetas, a_params, ds, a_params_calibrated, ds_calibrated\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Expanding Q-Matrix to question level...\nShape of expanded Q-Matrix: torch.Size([78712, 3])\ntrial 0 valid condition: True\nStarting Stage 1: Fitting item parameters (a_params and ds)...\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Stage 1: Calibrating Items:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | 0/200 [00:00<?, ?it/s]"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Stage 1: Calibrating Items: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:41<00:00,  4.83it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Stage 1 Finished.\nStarting Stage 2: Fitting person parameters (thetas)...\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Stage 2: Fitting Thetas: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 203.23it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Stage 2 Finished. Training complete.\ntrain auc: 0.6158990263938904\ntest auc: 0.6071275472640991\ntrain cttcorr: -0.7281585080721156\ntest cttcorr: -0.7226807794288592\n"
        }
      ],
      "execution_count": null,
      "metadata": {},
      "id": "d48933b6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "reeval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
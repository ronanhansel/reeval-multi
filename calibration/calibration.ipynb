{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e8cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.optim import LBFGS\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "import multiprocessing as mp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tueplots import bundles\n",
    "bundles.icml2024()\n",
    "\n",
    "from torchmetrics import AUROC\n",
    "auroc = AUROC(task=\"binary\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def visualize_response_matrix(results, value, filename):\n",
    "    # Extract the groups labels in the order of the columns\n",
    "    group_values = results.columns.get_level_values(\"scenario\")\n",
    "\n",
    "    # Identify the boundaries where the group changes\n",
    "    boundaries = []\n",
    "    for i in range(1, len(group_values)):\n",
    "        if group_values[i] != group_values[i - 1]:\n",
    "            boundaries.append(i - 0.5)  # using 0.5 to place the line between columns\n",
    "\n",
    "    # Visualize the results with a matrix: red is 0, white is -1 and blue is 1\n",
    "    cmap = mcolors.ListedColormap([\"white\", \"red\", \"blue\"])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    # Calculate midpoints for each group label\n",
    "    groups_list = list(group_values)\n",
    "    group_names = []\n",
    "    group_midpoints = []\n",
    "    current_group = groups_list[0]\n",
    "    start_index = 0\n",
    "    for i, grp in enumerate(groups_list):\n",
    "        if grp != current_group:\n",
    "            midpoint = (start_index + i - 1) / 2.0\n",
    "            group_names.append(current_group)\n",
    "            group_midpoints.append(midpoint)\n",
    "            current_group = grp\n",
    "            start_index = i\n",
    "    # Add the last group\n",
    "    midpoint = (start_index + len(groups_list) - 1) / 2.0\n",
    "    group_names.append(current_group)\n",
    "    group_midpoints.append(midpoint)\n",
    "\n",
    "    # Define the minimum spacing between labels (e.g., 100 units)\n",
    "    min_spacing = 100\n",
    "    last_label_pos = -float(\"inf\")\n",
    "    # Plot the matrix\n",
    "    with plt.rc_context(bundles.icml2024(usetex=True, family=\"serif\")):\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        cax = ax.matshow(value, aspect=\"auto\", cmap=cmap, norm=norm)\n",
    "\n",
    "        # Add vertical lines at each boundary\n",
    "        for b in boundaries:\n",
    "            ax.axvline(x=b, color=\"black\", linewidth=0.25, linestyle=\"--\", alpha=0.5)\n",
    "        \n",
    "        # Add group labels above the matrix, only if they're spaced enough apart\n",
    "        for name, pos in zip(group_names, group_midpoints):\n",
    "            if pos - last_label_pos >= min_spacing:\n",
    "                ax.text(pos, -5, name, ha='center', va='bottom', rotation=90, fontsize=3)\n",
    "                last_label_pos = pos\n",
    "\n",
    "        # Add model labels on the y-axis\n",
    "        ax.set_yticks(range(len(results.index)))\n",
    "        ax.set_yticklabels(results.index, fontsize=3)\n",
    "\n",
    "        # Add a colorbar\n",
    "        cbar = plt.colorbar(cax)\n",
    "        cbar.set_ticks([-1, 0, 1])\n",
    "        cbar.set_ticklabels([\"-1\", \"0\", \"1\"])\n",
    "        plt.savefig(filename, dpi=600, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "def trainer(parameters, optim, closure, n_iter=100, verbose=True):\n",
    "    pbar = tqdm(range(n_iter)) if verbose else range(n_iter)\n",
    "    for iteration in pbar:\n",
    "        if iteration > 0:\n",
    "            previous_parameters = [p.clone() for p in parameters]\n",
    "            previous_loss = loss.clone()\n",
    "        \n",
    "        loss = optim.step(closure)\n",
    "        \n",
    "        if iteration > 0:\n",
    "            d_loss = (previous_loss - loss).item()\n",
    "            d_parameters = sum(\n",
    "                torch.norm(prev - curr, p=2).item()\n",
    "                for prev, curr in zip(previous_parameters, parameters)\n",
    "            )\n",
    "            grad_norm = sum(torch.norm(p.grad, p=2).item() for p in parameters if p.grad is not None)\n",
    "            if verbose:\n",
    "                pbar.set_postfix({\"grad_norm\": grad_norm, \"d_parameter\": d_parameters, \"d_loss\": d_loss})\n",
    "            \n",
    "            if d_loss < 1e-5 and d_parameters < 1e-5 and grad_norm < 1e-5:\n",
    "                break\n",
    "    return parameters\n",
    "\n",
    "def compute_auc(probs, data, train_idtor, test_idtor):\n",
    "    train_probs = probs[train_idtor.bool()]\n",
    "    test_probs = probs[test_idtor.bool()]\n",
    "    train_labels = data[train_idtor.bool()]\n",
    "    test_labels = data[test_idtor.bool()]\n",
    "    train_auc = auroc(train_probs, train_labels)\n",
    "    test_auc = auroc(test_probs, test_labels)\n",
    "    print(f\"train auc: {train_auc}\")\n",
    "    print(f\"test auc: {test_auc}\")\n",
    "    \n",
    "    return train_auc, test_auc\n",
    "\n",
    "def compute_cttcorr(probs, data, train_idtor, test_idtor):\n",
    "    train_probs  = probs.clone()\n",
    "    test_probs   = probs.clone()\n",
    "    train_labels = data.clone()\n",
    "    test_labels  = data.clone()\n",
    "\n",
    "    train_mask = ~train_idtor.bool()\n",
    "    train_probs[train_mask]  = float('nan')\n",
    "    train_labels[train_mask] = float('nan')\n",
    "\n",
    "    test_mask = ~test_idtor.bool()\n",
    "    test_probs[test_mask]   = float('nan')\n",
    "    test_labels[test_mask]  = float('nan')\n",
    "    \n",
    "    train_prob_ctt = torch.nanmean(train_probs, dim=1).detach().cpu().numpy()\n",
    "    train_label_ctt = torch.nanmean(train_labels, dim=1).detach().cpu().numpy()\n",
    "    train_mask = ~np.isnan(train_prob_ctt) & ~np.isnan(train_label_ctt)\n",
    "    train_cttcorr = pearsonr(train_prob_ctt[train_mask], train_label_ctt[train_mask]).statistic\n",
    "    \n",
    "    test_prob_ctt = torch.nanmean(test_probs, dim=1).detach().cpu().numpy()\n",
    "    test_label_ctt = torch.nanmean(test_labels, dim=1).detach().cpu().numpy()\n",
    "    test_mask = ~np.isnan(test_prob_ctt) & ~np.isnan(test_label_ctt)\n",
    "    test_cttcorr = pearsonr(test_prob_ctt[test_mask], test_label_ctt[test_mask]).statistic\n",
    "    \n",
    "    print(f\"train cttcorr: {train_cttcorr}\")\n",
    "    print(f\"test cttcorr: {test_cttcorr}\")\n",
    "\n",
    "    return train_cttcorr, test_cttcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8bcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/resmat.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "dtype = torch.float64 if device.startswith(\"cuda\") else torch.float32\n",
    "\n",
    "# data_withnan, missing=nan\n",
    "# data_withneg1, missing=-1\n",
    "# data_with0, missing=0\n",
    "data_withnan = torch.tensor(results.values, dtype=dtype, device=device)\n",
    "data_idtor = (~torch.isnan(data_withnan)).to(dtype)\n",
    "data_withneg1 = data_withnan.nan_to_num(nan=-1.0)\n",
    "data_with0 = data_withneg1 * data_idtor\n",
    "data_with0 = data_with0.nan_to_num(nan=0.0)\n",
    "n_test_takers, n_items = data_with0.shape\n",
    "scenarios = results.columns.get_level_values(\"scenario\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001a8b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial 0 valid condition: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:24<?, ?it/s]\n",
      "  0%|          | 0/2 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/reeval/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mclosure_z_i\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(thetas_nuisance[:, :, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m z_i[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :])\n\u001b[0;32m---> 25\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[43mBernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mtrain_idtor_batch)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/reeval/lib/python3.10/site-packages/torch/distributions/bernoulli.py:112\u001b[0m, in \u001b[0;36mBernoulli.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    111\u001b[0m logits, value \u001b[38;5;241m=\u001b[39m broadcast_all(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits, value)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/reeval/lib/python3.10/site-packages/torch/nn/functional.py:3244\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 31.70 GB, other allocations: 672.00 KB, max allowed: 36.27 GB). Tried to allocate 5.11 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 28\u001b[0m     z_i_optimized \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_z_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure_z_i\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     29\u001b[0m     optimized_zs\u001b[38;5;241m.\u001b[39mappend(z_i_optimized)\n\u001b[1;32m     30\u001b[0m zs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(optimized_zs)\n",
      "Cell \u001b[0;32mIn[1], line 101\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(parameters, optim, closure, n_iter, verbose)\u001b[0m\n\u001b[1;32m     98\u001b[0m     previous_parameters \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters]\n\u001b[1;32m     99\u001b[0m     previous_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 101\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     d_loss \u001b[38;5;241m=\u001b[39m (previous_loss \u001b[38;5;241m-\u001b[39m loss)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/reeval/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/reeval/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/reeval/lib/python3.10/site-packages/torch/optim/lbfgs.py:323\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    320\u001b[0m state\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m orig_loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(orig_loss)\n\u001b[1;32m    325\u001b[0m current_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/reeval/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data_idtor = train_idtor + test_idtor\n",
    "# apply random train/test mask to the matrix, and ensure no one row or column is fully masked\n",
    "valid_condition = False\n",
    "trial = 0\n",
    "while not valid_condition:\n",
    "    train_idtor = torch.bernoulli(data_idtor * 0.8).int()\n",
    "    test_idtor = data_idtor - train_idtor\n",
    "    valid_condition = (train_idtor.sum(axis=1) != 0).all() and (train_idtor.sum(axis=0) != 0).all()\n",
    "    print(f\"trial {trial} valid condition: {valid_condition}\")\n",
    "    trial += 1\n",
    "\n",
    "# fit z\n",
    "B = 50000\n",
    "optimized_zs = []\n",
    "thetas_nuisance = torch.randn(150, n_test_takers, device=device)\n",
    "for i in tqdm(range(0, n_items, B)):\n",
    "    data_batch = data_with0[:, i:i+B]\n",
    "    train_idtor_batch = train_idtor[:, i:i+B]\n",
    "    current_B = data_batch.shape[1]\n",
    "    z_i = torch.randn(current_B, requires_grad=True, device=device)\n",
    "    optim_z_i = LBFGS([z_i], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "    def closure_z_i():\n",
    "        optim_z_i.zero_grad()\n",
    "        probs = torch.sigmoid(thetas_nuisance[:, :, None] + z_i[None, None, :])\n",
    "        loss = -(Bernoulli(probs=probs).log_prob(data_batch)*train_idtor_batch).mean()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    z_i_optimized = trainer([z_i], optim_z_i, closure_z_i)[0].detach()\n",
    "    optimized_zs.append(z_i_optimized)\n",
    "zs = torch.cat(optimized_zs)\n",
    "\n",
    "# fit theta\n",
    "thetas = torch.randn(n_test_takers, requires_grad=True, device=device)\n",
    "optim_theta = LBFGS([thetas], lr=0.1, max_iter=20, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "def closure_theta():\n",
    "    optim_theta.zero_grad()\n",
    "    probs = torch.sigmoid(thetas[:, None] + zs[None, :])\n",
    "    loss = -(Bernoulli(probs=probs).log_prob(data_with0)*train_idtor).mean()\n",
    "    loss.backward()\n",
    "    return loss\n",
    "thetas = trainer([thetas], optim_theta, closure_theta)[0]\n",
    "\n",
    "# calculate metrics\n",
    "probs = torch.sigmoid(thetas[:, None] + zs[None, :])\n",
    "\n",
    "train_auc, test_auc = compute_auc(probs, data_with0, train_idtor, test_idtor)\n",
    "metric_results[\"combined_data\"][\"train_auc\"] = train_auc.item()\n",
    "metric_results[\"combined_data\"][\"test_auc\"] = test_auc.item()\n",
    "\n",
    "train_cttcorr, test_cttcorr = compute_cttcorr(probs, data_with0, train_idtor, test_idtor)\n",
    "metric_results[\"combined_data\"][\"train_cttcorr\"] = train_cttcorr.item()\n",
    "metric_results[\"combined_data\"][\"test_cttcorr\"] = test_cttcorr.item()\n",
    "\n",
    "del optim_theta, thetas, z_i, thetas_nuisance, optim_z_i\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralIRT_1PL(nn.Module):\n",
    "    def __init__(self, n_test_takers, n_items, n_dimensions, q_matrix):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Person embedding layer -> learns the multidimensional thetas\n",
    "        self.person_embedding = nn.Embedding(n_test_takers, n_dimensions)\n",
    "        \n",
    "        # <<< REMOVED: The item_a_embedding layer is gone for the 1PL model >>>\n",
    "        \n",
    "        # Item difficulty embedding layer -> learns the 'b' parameters\n",
    "        self.item_b_embedding = nn.Embedding(n_items, 1)\n",
    "        \n",
    "        # <<< NEW: Store the fixed Q-matrix as a non-trainable buffer >>>\n",
    "        # This is the correct way to include fixed data in a PyTorch model.\n",
    "        self.register_buffer('q_matrix', q_matrix)\n",
    "\n",
    "    def forward(self, person_ids, item_ids):\n",
    "        # Look up the vectors for the given persons and items\n",
    "        theta = self.person_embedding(person_ids)\n",
    "        b = self.item_b_embedding(item_ids).squeeze()\n",
    "        \n",
    "        # <<< NEW: Look up the Q-matrix vector for the given items >>>\n",
    "        q_vector = self.q_matrix[item_ids]\n",
    "        \n",
    "        # --- The MIRT 1PL Formula ---\n",
    "        # 1. Apply the Q-matrix to select the relevant theta dimensions\n",
    "        effective_theta = theta * q_vector\n",
    "        \n",
    "        # 2. Sum the relevant abilities (this is the dot product with a=1)\n",
    "        #    and subtract the item difficulty 'b'\n",
    "        logits = torch.sum(effective_theta, dim=1) - b\n",
    "        \n",
    "        # Apply sigmoid to get the probability\n",
    "        prob = torch.sigmoid(logits)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43780f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build the Q-Matrix for your MASTER TEST ---\n",
    "# Assume master_test_df is your (120, ...) DataFrame with the 'component' column\n",
    "n_dimensions = 6 # Your MASTER TEST has 6 components\n",
    "\n",
    "component_names = master_test_df['component'].unique()\n",
    "Q_matrix_df = pd.get_dummies(master_test_df['component'])\n",
    "Q_matrix_df = Q_matrix_df[component_names]\n",
    "Q_matrix_tensor = torch.tensor(Q_matrix_df.values, device=device, dtype=torch.float32)\n",
    "\n",
    "print(f\"Shape of Q-Matrix: {Q_matrix_tensor.shape}\") # Should be (120, 6)\n",
    "\n",
    "# --- Prepare the \"long format\" training data (same as before) ---\n",
    "# Assume 'final_test_data_matrix' (183, 120) and 'data_idtor' are available\n",
    "# ... (code to create 'training_data' goes here) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcffcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# --- Setup ---\n",
    "# <<< Instantiate the new 1PL model and pass the Q-matrix to it >>>\n",
    "model = NeuralIRT_1PL(n_test_takers, n_items, n_dimensions, q_matrix=Q_matrix_tensor).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Use a DataLoader for efficient batching (same as before)\n",
    "dataset = TensorDataset(training_data[:, 0], training_data[:, 1], training_data[:, 2].float())\n",
    "data_loader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# --- Training (this loop is exactly the same as before) ---\n",
    "n_epochs = 5\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for person_ids, item_ids, labels in tqdm(data_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        person_ids, item_ids, labels = person_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(person_ids, item_ids)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# --- Get your final multidimensional thetas ---\n",
    "model.eval()\n",
    "final_thetas_1pl = model.person_embedding.weight.detach().cpu().numpy()\n",
    "print(f\"\\nShape of final 1PL thetas: {final_thetas_1pl.shape}\") # Should be (183, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

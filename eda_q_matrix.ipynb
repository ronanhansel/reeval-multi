{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48ed8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e90eaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/resmat.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af07a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.multi.MultiIndex'>\n"
     ]
    }
   ],
   "source": [
    "results = df.columns\n",
    "\n",
    "print(type(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a64be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenList(['input.text', 'scenario', 'benchmark'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82f7c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scenario = df.columns.get_level_values('scenario').unique().to_list()\n",
    "benchmark = df.columns.get_level_values('benchmark').unique().to_list()\n",
    "\n",
    "scenario_benchmark_combinations = df.columns.to_frame()[['scenario', 'benchmark']].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5122410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsat_qa</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truthful_qa</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synthetic_reasoning</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>babi_qa</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikifact</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bbq</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thai_exam</td>\n",
       "      <td>thaiexam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dyck_language_np=3</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>legal_support</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>civil_comments</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>legalbench</td>\n",
       "      <td>lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>raft</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>air_bench_2024</td>\n",
       "      <td>air-bench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>math</td>\n",
       "      <td>lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gsm</td>\n",
       "      <td>lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>boolq</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>mmlu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entity_matching</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>entity_data_imputation</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>commonsense</td>\n",
       "      <td>lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>imdb</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  scenario  benchmark\n",
       "0                  lsat_qa    classic\n",
       "1              truthful_qa    classic\n",
       "2      synthetic_reasoning    classic\n",
       "3                  babi_qa    classic\n",
       "4                 wikifact    classic\n",
       "5                      bbq    classic\n",
       "6                thai_exam   thaiexam\n",
       "7       dyck_language_np=3    classic\n",
       "8            legal_support    classic\n",
       "9           civil_comments    classic\n",
       "10              legalbench       lite\n",
       "11                    raft    classic\n",
       "12          air_bench_2024  air-bench\n",
       "13                    math       lite\n",
       "14                  med_qa       lite\n",
       "15                     gsm       lite\n",
       "16                   boolq    classic\n",
       "17                    mmlu       mmlu\n",
       "18         entity_matching    classic\n",
       "19  entity_data_imputation    classic\n",
       "20             commonsense       lite\n",
       "21                    imdb    classic"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = pd.DataFrame(scenario_benchmark_combinations, columns=['scenario', 'benchmark'])\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "817a7eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsat_qa',\n",
       " 'truthful_qa',\n",
       " 'synthetic_reasoning',\n",
       " 'babi_qa',\n",
       " 'wikifact',\n",
       " 'bbq',\n",
       " 'thai_exam',\n",
       " 'dyck_language_np=3',\n",
       " 'legal_support',\n",
       " 'civil_comments',\n",
       " 'legalbench',\n",
       " 'raft',\n",
       " 'air_bench_2024',\n",
       " 'math',\n",
       " 'med_qa',\n",
       " 'gsm',\n",
       " 'boolq',\n",
       " 'mmlu',\n",
       " 'entity_matching',\n",
       " 'entity_data_imputation',\n",
       " 'commonsense',\n",
       " 'imdb']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b97d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "def add_ability_tags_to_df(df):\n",
    "    \"\"\"\n",
    "    Adds an 'ability_tags' column to a DataFrame based on its 'scenario' column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with a 'scenario' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new 'ability_tags' column.\n",
    "    \"\"\"\n",
    "    # Mapping of dataset names to one or more ability levels.\n",
    "    ability_mapping = {\n",
    "        'truthful_qa': ['Foundational Knowledge'],\n",
    "        'wikifact': ['Foundational Knowledge'],\n",
    "        'lsat_qa': ['Analytical Reasoning'],\n",
    "        'synthetic_reasoning': ['Analytical Reasoning'],\n",
    "        'babi_qa': ['Analytical Reasoning'],\n",
    "        'bbq': ['Analytical Reasoning'],\n",
    "        'dyck_language_np=3': ['Analytical Reasoning'],\n",
    "        'civil_comments': ['Analytical Reasoning'],\n",
    "        'raft': ['Analytical Reasoning'],\n",
    "        'math': ['Analytical Reasoning'],\n",
    "        'gsm': ['Analytical Reasoning'],\n",
    "        'entity_matching': ['Analytical Reasoning'],\n",
    "        'entity_data_imputation': ['Analytical Reasoning'],\n",
    "        'commonsense': ['Analytical Reasoning'],\n",
    "        'imdb': ['Analytical Reasoning'],\n",
    "        'legal_support': ['Higher-Order Skills', 'Analytical Reasoning'],\n",
    "        'legalbench': ['Higher-Order Skills', 'Analytical Reasoning'],\n",
    "        'air_bench_2024': ['Higher-Order Skills'],\n",
    "        'med_qa': ['Foundational Knowledge', 'Higher-Order Skills'],\n",
    "        'boolq': ['Foundational Knowledge', 'Analytical Reasoning'],\n",
    "        'mmlu': ['Foundational Knowledge', 'Analytical Reasoning', 'Higher-Order Skills'],\n",
    "        'thai_exam': ['Foundational Knowledge', 'Analytical Reasoning'],\n",
    "    }\n",
    "\n",
    "    # Use the .get() method to avoid errors for unclassified scenarios.\n",
    "    # It will return 'Unclassified' if a scenario is not in our mapping.\n",
    "    df['ability_tags'] = df['scenario'].apply(\n",
    "        lambda x: ability_mapping.get(x, ['Unclassified'])\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_ability_tags_to_df_2d(df):\n",
    "    \"\"\"\n",
    "    Adds a 2D 'ability_tags' column based on a Linguistic vs. Scientific framework.\n",
    "    \"\"\"\n",
    "    # Mapping of scenarios to the two new domain dimensions.\n",
    "    ability_mapping_2d_domain = {\n",
    "        # Primarily Linguistic & Logical Reasoning (LLR)\n",
    "        'truthful_qa': ['Linguistic & Logical Reasoning'],\n",
    "        'wikifact': ['Linguistic & Logical Reasoning'],\n",
    "        'lsat_qa': ['Linguistic & Logical Reasoning'],\n",
    "        'synthetic_reasoning': ['Linguistic & Logical Reasoning'],\n",
    "        'babi_qa': ['Linguistic & Logical Reasoning'],\n",
    "        'bbq': ['Linguistic & Logical Reasoning'],\n",
    "        'dyck_language_np=3': ['Linguistic & Logical Reasoning'],\n",
    "        'civil_comments': ['Linguistic & Logical Reasoning'],\n",
    "        'raft': ['Linguistic & Logical Reasoning'],\n",
    "        'entity_matching': ['Linguistic & Logical Reasoning'],\n",
    "        'entity_data_imputation': ['Linguistic & Logical Reasoning'],\n",
    "        'commonsense': ['Linguistic & Logical Reasoning'],\n",
    "        'imdb': ['Linguistic & Logical Reasoning'],\n",
    "        'legal_support': ['Linguistic & Logical Reasoning'],\n",
    "        'legalbench': ['Linguistic & Logical Reasoning'],\n",
    "        'boolq': ['Linguistic & Logical Reasoning'],\n",
    "\n",
    "        # Primarily Scientific & Quantitative Reasoning (SQR)\n",
    "        'math': ['Scientific & Quantitative Reasoning'],\n",
    "        'gsm': ['Scientific & Quantitative Reasoning'],\n",
    "        'med_qa': ['Scientific & Quantitative Reasoning'],\n",
    "\n",
    "        # Requiring both LLR and SQR\n",
    "        'air_bench_2024': ['Linguistic & Logical Reasoning', 'Scientific & Quantitative Reasoning'],\n",
    "        'mmlu': ['Linguistic & Logical Reasoning', 'Scientific & Quantitative Reasoning'],\n",
    "        'thai_exam': ['Linguistic & Logical Reasoning', 'Scientific & Quantitative Reasoning'],\n",
    "    }\n",
    "\n",
    "    df['ability_tags'] = df['scenario'].apply(\n",
    "        lambda x: ability_mapping_2d_domain.get(x, ['Unclassified'])\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "tests_with_tags = add_ability_tags_to_df_2d(tests)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "one_hot_encoded_df = pd.DataFrame(\n",
    "    mlb.fit_transform(tests_with_tags['ability_tags']),\n",
    "    columns=mlb.classes_,\n",
    "    index=tests_with_tags.index\n",
    ")\n",
    "final_df = pd.concat([tests_with_tags, one_hot_encoded_df], axis=1).reset_index(names=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a8bc5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>scenario</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>ability_tags</th>\n",
       "      <th>Linguistic &amp; Logical Reasoning</th>\n",
       "      <th>Scientific &amp; Quantitative Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lsat_qa</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>truthful_qa</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>synthetic_reasoning</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>babi_qa</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>wikifact</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>bbq</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>thai_exam</td>\n",
       "      <td>thaiexam</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning, Scientific &amp; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>dyck_language_np=3</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>legal_support</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>civil_comments</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>legalbench</td>\n",
       "      <td>lite</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>raft</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>air_bench_2024</td>\n",
       "      <td>air-bench</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning, Scientific &amp; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>math</td>\n",
       "      <td>lite</td>\n",
       "      <td>[Scientific &amp; Quantitative Reasoning]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>med_qa</td>\n",
       "      <td>lite</td>\n",
       "      <td>[Scientific &amp; Quantitative Reasoning]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>gsm</td>\n",
       "      <td>lite</td>\n",
       "      <td>[Scientific &amp; Quantitative Reasoning]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>boolq</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>mmlu</td>\n",
       "      <td>mmlu</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning, Scientific &amp; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>entity_matching</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>entity_data_imputation</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>commonsense</td>\n",
       "      <td>lite</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>imdb</td>\n",
       "      <td>classic</td>\n",
       "      <td>[Linguistic &amp; Logical Reasoning]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                scenario  benchmark  \\\n",
       "0       0                 lsat_qa    classic   \n",
       "1       1             truthful_qa    classic   \n",
       "2       2     synthetic_reasoning    classic   \n",
       "3       3                 babi_qa    classic   \n",
       "4       4                wikifact    classic   \n",
       "5       5                     bbq    classic   \n",
       "6       6               thai_exam   thaiexam   \n",
       "7       7      dyck_language_np=3    classic   \n",
       "8       8           legal_support    classic   \n",
       "9       9          civil_comments    classic   \n",
       "10     10              legalbench       lite   \n",
       "11     11                    raft    classic   \n",
       "12     12          air_bench_2024  air-bench   \n",
       "13     13                    math       lite   \n",
       "14     14                  med_qa       lite   \n",
       "15     15                     gsm       lite   \n",
       "16     16                   boolq    classic   \n",
       "17     17                    mmlu       mmlu   \n",
       "18     18         entity_matching    classic   \n",
       "19     19  entity_data_imputation    classic   \n",
       "20     20             commonsense       lite   \n",
       "21     21                    imdb    classic   \n",
       "\n",
       "                                         ability_tags  \\\n",
       "0                    [Linguistic & Logical Reasoning]   \n",
       "1                    [Linguistic & Logical Reasoning]   \n",
       "2                    [Linguistic & Logical Reasoning]   \n",
       "3                    [Linguistic & Logical Reasoning]   \n",
       "4                    [Linguistic & Logical Reasoning]   \n",
       "5                    [Linguistic & Logical Reasoning]   \n",
       "6   [Linguistic & Logical Reasoning, Scientific & ...   \n",
       "7                    [Linguistic & Logical Reasoning]   \n",
       "8                    [Linguistic & Logical Reasoning]   \n",
       "9                    [Linguistic & Logical Reasoning]   \n",
       "10                   [Linguistic & Logical Reasoning]   \n",
       "11                   [Linguistic & Logical Reasoning]   \n",
       "12  [Linguistic & Logical Reasoning, Scientific & ...   \n",
       "13              [Scientific & Quantitative Reasoning]   \n",
       "14              [Scientific & Quantitative Reasoning]   \n",
       "15              [Scientific & Quantitative Reasoning]   \n",
       "16                   [Linguistic & Logical Reasoning]   \n",
       "17  [Linguistic & Logical Reasoning, Scientific & ...   \n",
       "18                   [Linguistic & Logical Reasoning]   \n",
       "19                   [Linguistic & Logical Reasoning]   \n",
       "20                   [Linguistic & Logical Reasoning]   \n",
       "21                   [Linguistic & Logical Reasoning]   \n",
       "\n",
       "    Linguistic & Logical Reasoning  Scientific & Quantitative Reasoning  \n",
       "0                                1                                    0  \n",
       "1                                1                                    0  \n",
       "2                                1                                    0  \n",
       "3                                1                                    0  \n",
       "4                                1                                    0  \n",
       "5                                1                                    0  \n",
       "6                                1                                    1  \n",
       "7                                1                                    0  \n",
       "8                                1                                    0  \n",
       "9                                1                                    0  \n",
       "10                               1                                    0  \n",
       "11                               1                                    0  \n",
       "12                               1                                    1  \n",
       "13                               0                                    1  \n",
       "14                               0                                    1  \n",
       "15                               0                                    1  \n",
       "16                               1                                    0  \n",
       "17                               1                                    1  \n",
       "18                               1                                    0  \n",
       "19                               1                                    0  \n",
       "20                               1                                    0  \n",
       "21                               1                                    0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "804a3bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ability_tags = ['Linguistic & Logical Reasoning', 'Scientific & Quantitative Reasoning']\n",
    "ability_tags_str = '_'.join(ability_tags).replace(' ', '_')\n",
    "name_file = f\"qmat_2d_{ability_tags_str}\"\n",
    "abimap = final_df[ability_tags].to_numpy()\n",
    "abimap.tofile(f\"data/{name_file}.npy\")\n",
    "\n",
    "# To load it back correctly, you need to reshape it\n",
    "loaded_abimap = np.fromfile(f\"data/{name_file}.npy\", dtype=abimap.dtype).reshape(22, 2)\n",
    "loaded_abimap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7272fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.columns.values.tolist()\n",
    "sm = []\n",
    "for v in values:\n",
    "  sm.append(final_df.loc[final_df['scenario'] == v[1], 'index'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb8d6d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 21, 21, 21], shape=(78712,), dtype=int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sm_n = np.array(sm, dtype=np.int32)  # Ensure integer type\n",
    "sm_n.tofile(f\"data/scenario_map_2d_{ability_tags_str}.npy\")\n",
    "sm_n  # This will show the integer array\n",
    "\n",
    "# When loading, specify the dtype to match what was saved\n",
    "loaded = np.fromfile(f\"data/scenario_map_2d_{ability_tags_str}.npy\", dtype=np.int32)\n",
    "loaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

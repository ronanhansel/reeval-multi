{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.optim import LBFGS\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "import multiprocessing as mp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tueplots import bundles\n",
    "bundles.icml2024()\n",
    "\n",
    "from torchmetrics import AUROC\n",
    "auroc = AUROC(task=\"binary\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def visualize_response_matrix(results, value, filename):\n",
    "    # Extract the groups labels in the order of the columns\n",
    "    group_values = results.columns.get_level_values(\"scenario\")\n",
    "\n",
    "    # Identify the boundaries where the group changes\n",
    "    boundaries = []\n",
    "    for i in range(1, len(group_values)):\n",
    "        if group_values[i] != group_values[i - 1]:\n",
    "            boundaries.append(i - 0.5)  # using 0.5 to place the line between columns\n",
    "\n",
    "    # Visualize the results with a matrix: red is 0, white is -1 and blue is 1\n",
    "    cmap = mcolors.ListedColormap([\"white\", \"red\", \"blue\"])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    # Calculate midpoints for each group label\n",
    "    groups_list = list(group_values)\n",
    "    group_names = []\n",
    "    group_midpoints = []\n",
    "    current_group = groups_list[0]\n",
    "    start_index = 0\n",
    "    for i, grp in enumerate(groups_list):\n",
    "        if grp != current_group:\n",
    "            midpoint = (start_index + i - 1) / 2.0\n",
    "            group_names.append(current_group)\n",
    "            group_midpoints.append(midpoint)\n",
    "            current_group = grp\n",
    "            start_index = i\n",
    "    # Add the last group\n",
    "    midpoint = (start_index + len(groups_list) - 1) / 2.0\n",
    "    group_names.append(current_group)\n",
    "    group_midpoints.append(midpoint)\n",
    "\n",
    "    # Define the minimum spacing between labels (e.g., 100 units)\n",
    "    min_spacing = 100\n",
    "    last_label_pos = -float(\"inf\")\n",
    "    # Plot the matrix\n",
    "    with plt.rc_context(bundles.icml2024(usetex=True, family=\"serif\")):\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        cax = ax.matshow(value, aspect=\"auto\", cmap=cmap, norm=norm)\n",
    "\n",
    "        # Add vertical lines at each boundary\n",
    "        for b in boundaries:\n",
    "            ax.axvline(x=b, color=\"black\", linewidth=0.25, linestyle=\"--\", alpha=0.5)\n",
    "        \n",
    "        # Add group labels above the matrix, only if they're spaced enough apart\n",
    "        for name, pos in zip(group_names, group_midpoints):\n",
    "            if pos - last_label_pos >= min_spacing:\n",
    "                ax.text(pos, -5, name, ha='center', va='bottom', rotation=90, fontsize=3)\n",
    "                last_label_pos = pos\n",
    "\n",
    "        # Add model labels on the y-axis\n",
    "        ax.set_yticks(range(len(results.index)))\n",
    "        ax.set_yticklabels(results.index, fontsize=3)\n",
    "\n",
    "        # Add a colorbar\n",
    "        cbar = plt.colorbar(cax)\n",
    "        cbar.set_ticks([-1, 0, 1])\n",
    "        cbar.set_ticklabels([\"-1\", \"0\", \"1\"])\n",
    "        plt.savefig(filename, dpi=600, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "def trainer(parameters, optim, closure, n_iter=100, verbose=True):\n",
    "    pbar = tqdm(range(n_iter)) if verbose else range(n_iter)\n",
    "    for iteration in pbar:\n",
    "        if iteration > 0:\n",
    "            previous_parameters = [p.clone() for p in parameters]\n",
    "            previous_loss = loss.clone()\n",
    "        \n",
    "        loss = optim.step(closure)\n",
    "        \n",
    "        if iteration > 0:\n",
    "            d_loss = (previous_loss - loss).item()\n",
    "            d_parameters = sum(\n",
    "                torch.norm(prev - curr, p=2).item()\n",
    "                for prev, curr in zip(previous_parameters, parameters)\n",
    "            )\n",
    "            grad_norm = sum(torch.norm(p.grad, p=2).item() for p in parameters if p.grad is not None)\n",
    "            if verbose:\n",
    "                pbar.set_postfix({\"grad_norm\": grad_norm, \"d_parameter\": d_parameters, \"d_loss\": d_loss})\n",
    "            \n",
    "            if d_loss < 1e-5 and d_parameters < 1e-5 and grad_norm < 1e-5:\n",
    "                break\n",
    "    return parameters\n",
    "\n",
    "def compute_auc(probs, data, train_idtor, test_idtor):\n",
    "    train_probs = probs[train_idtor.bool()]\n",
    "    test_probs = probs[test_idtor.bool()]\n",
    "    train_labels = data[train_idtor.bool()]\n",
    "    test_labels = data[test_idtor.bool()]\n",
    "    train_auc = auroc(train_probs, train_labels)\n",
    "    test_auc = auroc(test_probs, test_labels)\n",
    "    print(f\"train auc: {train_auc}\")\n",
    "    print(f\"test auc: {test_auc}\")\n",
    "    \n",
    "    return train_auc, test_auc\n",
    "\n",
    "def compute_cttcorr(probs, data, train_idtor, test_idtor):\n",
    "    train_probs  = probs.clone()\n",
    "    test_probs   = probs.clone()\n",
    "    train_labels = data.clone()\n",
    "    test_labels  = data.clone()\n",
    "\n",
    "    train_mask = ~train_idtor.bool()\n",
    "    train_probs[train_mask]  = float('nan')\n",
    "    train_labels[train_mask] = float('nan')\n",
    "\n",
    "    test_mask = ~test_idtor.bool()\n",
    "    test_probs[test_mask]   = float('nan')\n",
    "    test_labels[test_mask]  = float('nan')\n",
    "    \n",
    "    train_prob_ctt = torch.nanmean(train_probs, dim=1).detach().cpu().numpy()\n",
    "    train_label_ctt = torch.nanmean(train_labels, dim=1).detach().cpu().numpy()\n",
    "    train_mask = ~np.isnan(train_prob_ctt) & ~np.isnan(train_label_ctt)\n",
    "    train_cttcorr = pearsonr(train_prob_ctt[train_mask], train_label_ctt[train_mask]).statistic\n",
    "    \n",
    "    test_prob_ctt = torch.nanmean(test_probs, dim=1).detach().cpu().numpy()\n",
    "    test_label_ctt = torch.nanmean(test_labels, dim=1).detach().cpu().numpy()\n",
    "    test_mask = ~np.isnan(test_prob_ctt) & ~np.isnan(test_label_ctt)\n",
    "    test_cttcorr = pearsonr(test_prob_ctt[test_mask], test_label_ctt[test_mask]).statistic\n",
    "    \n",
    "    print(f\"train cttcorr: {train_cttcorr}\")\n",
    "    print(f\"test cttcorr: {test_cttcorr}\")\n",
    "\n",
    "    return train_cttcorr, test_cttcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ddf5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading response matrix...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.special import expit # Numerically stable sigmoid function\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# --- PyTorch and Metrics Imports (from your reference code) ---\n",
    "import torch\n",
    "from torchmetrics import AUROC\n",
    "auroc = AUROC(task=\"binary\")\n",
    "# --- End of Imports ---\n",
    "# ===================================================================\n",
    "# == Step 1: Load Data and Create Train/Test Split\n",
    "# ===================================================================\n",
    "print(\"Loading response matrix...\")\n",
    "resmat = pd.read_pickle(\"../data/resmat_2000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8d1940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into 910536 train samples and 227634 test samples.\n",
      "\n",
      "Training SVD model with k=8...\n",
      "\n",
      "Converting results to PyTorch Tensors for evaluation...\n",
      "\n",
      "--- Running Final Evaluations ---\n",
      "train auc: 0.9263309240341187\n",
      "test auc: 0.8913356065750122\n",
      "train cttcorr: 0.9637015461921692\n",
      "test cttcorr: 0.9530106782913208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float32(0.96370155), np.float32(0.9530107))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the locations (row, col indices) of all non-missing values\n",
    "non_nan_indices = np.argwhere(resmat.notna().values)\n",
    "\n",
    "# Randomly shuffle these indices\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(non_nan_indices)\n",
    "\n",
    "# Decide on the split size\n",
    "test_size = int(len(non_nan_indices) * 0.20)\n",
    "test_indices = non_nan_indices[:test_size]\n",
    "train_indices = non_nan_indices[test_size:]\n",
    "\n",
    "# Create the training matrix by hiding the test data\n",
    "train_resmat = resmat.copy()\n",
    "test_rows, test_cols = train_resmat.values.shape[0], train_resmat.values.shape[1]\n",
    "train_resmat.values[test_indices[:, 0], test_indices[:, 1]] = np.nan\n",
    "\n",
    "print(f\"Split data into {len(train_indices)} train samples and {len(test_indices)} test samples.\")\n",
    "\n",
    "# Impute the training data for SVD\n",
    "imputed_train_resmat = train_resmat.fillna(0)\n",
    "\n",
    "# ===================================================================\n",
    "# == Step 2: Train SVD Model and Get Predictions\n",
    "# ===================================================================\n",
    "OPTIMAL_K = 8\n",
    "print(f\"\\nTraining SVD model with k={OPTIMAL_K}...\")\n",
    "\n",
    "svd = TruncatedSVD(n_components=OPTIMAL_K, random_state=42)\n",
    "svd.fit(imputed_train_resmat)\n",
    "\n",
    "# Reconstruct the full matrix and convert to probabilities\n",
    "reconstructed_matrix = svd.inverse_transform(svd.transform(imputed_train_resmat))\n",
    "probs_matrix_np = expit(reconstructed_matrix)\n",
    "\n",
    "# ===================================================================\n",
    "# == Step 3: Prepare Data for Evaluation (NumPy and PyTorch)\n",
    "# ===================================================================\n",
    "# Ground truth data as a numpy array\n",
    "data_np = resmat.fillna(0).values\n",
    "\n",
    "# Create boolean masks (numpy)\n",
    "train_idtor_np = np.zeros_like(data_np, dtype=bool)\n",
    "test_idtor_np = np.zeros_like(data_np, dtype=bool)\n",
    "train_idtor_np[train_indices[:, 0], train_indices[:, 1]] = True\n",
    "test_idtor_np[test_indices[:, 0], test_indices[:, 1]] = True\n",
    "\n",
    "# --- NEW: Convert NumPy arrays to PyTorch tensors for compatibility ---\n",
    "print(\"\\nConverting results to PyTorch Tensors for evaluation...\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "probs_tensor = torch.tensor(probs_matrix_np, dtype=torch.float32, device=device)\n",
    "data_tensor = torch.tensor(data_np, dtype=torch.float32, device=device)\n",
    "train_idtor_tensor = torch.tensor(train_idtor_np, dtype=torch.int, device=device)\n",
    "test_idtor_tensor = torch.tensor(test_idtor_np, dtype=torch.int, device=device)\n",
    "# --- End of Conversion ---\n",
    "\n",
    "print(\"\\n--- Running Final Evaluations ---\")\n",
    "compute_auc(probs_tensor, data_tensor, train_idtor_tensor, test_idtor_tensor)\n",
    "compute_cttcorr(probs_tensor, data_tensor, train_idtor_tensor, test_idtor_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
